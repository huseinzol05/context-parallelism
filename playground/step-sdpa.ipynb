{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce1923b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xformers.ops.fmha import (\n",
    "    memory_efficient_attention_forward,\n",
    "    memory_efficient_attention_backward, \n",
    "    memory_efficient_attention_partial,\n",
    "    merge_attentions\n",
    ")\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a35524dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "head_num = 16\n",
    "dim = 128\n",
    "seq_len = 100\n",
    "chunk_size = 5\n",
    "batch_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ddecb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = torch.randn(batch_size, head_num, 1, dim).cuda().to(torch.bfloat16)\n",
    "k = torch.randn(batch_size, head_num, seq_len, dim).cuda().to(torch.bfloat16)\n",
    "v = torch.randn(batch_size, head_num, seq_len, dim).cuda().to(torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d45fc22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 10 ms, total: 10 ms\n",
      "Wall time: 28.7 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16, 1, 128])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "out_dot = torch.nn.functional.scaled_dot_product_attention(q, k, v)\n",
    "out_dot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "061c8c65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 100, 16, 128])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_ = q.transpose(1, 2)\n",
    "k_ = k.transpose(1, 2)\n",
    "v_ = v.transpose(1, 2)\n",
    "v_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd8c60d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# means we split attention into 5 partitions and incrementally calculate it\n",
    "k_chunks = k_.chunk(chunk_size, dim = 1)\n",
    "v_chunks = v_.chunk(chunk_size, dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5105ca88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 16, 128])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c5b74a0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16.3 ms, sys: 42.2 ms, total: 58.5 ms\n",
      "Wall time: 71.1 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16, 1, 128])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# https://github.com/ScalingIntelligence/hydragen/blob/main/hydragen/attention.py#L21\n",
    "outs, lses = [], []\n",
    "for i in range(len(k_chunks)):\n",
    "    out_, lse_ = memory_efficient_attention_partial(q_, k_chunks[i], v_chunks[i])\n",
    "    outs.append(out_)\n",
    "    lses.append(lse_)\n",
    "    \n",
    "outs = torch.stack(outs)\n",
    "lses = torch.stack(lses)\n",
    "\n",
    "max_lse = lses.max(0).values\n",
    "lse_full = (max_lse + (lses - max_lse[None]).exp().sum(dim=0).log())\n",
    "\n",
    "adjust_factors = (lses - max_lse[None]).exp()\n",
    "adjust_factors = adjust_factors.transpose(2, 3).unsqueeze(-1)\n",
    "new_denominator = adjust_factors.sum(0)\n",
    "out_offload = ((outs * adjust_factors).sum(0) / new_denominator).transpose(1, 2)\n",
    "out_offload.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f025889",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.2976, -0.2209, -0.2320,  ...,  0.2711, -0.0087,  0.0849]],\n",
       "\n",
       "         [[ 0.1269,  0.0716,  0.0772,  ...,  0.0294, -0.2892,  0.0221]],\n",
       "\n",
       "         [[ 0.1076, -0.1437, -0.0286,  ..., -0.0479, -0.0791, -0.0275]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.0288,  0.0269, -0.2649,  ...,  0.0051,  0.1333, -0.0487]],\n",
       "\n",
       "         [[-0.0036,  0.0536,  0.0127,  ..., -0.0956, -0.2699,  0.1205]],\n",
       "\n",
       "         [[ 0.0820, -0.2063,  0.0273,  ...,  0.0770,  0.2213, -0.1132]]]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_offload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "285ec478",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 1.1930e-03, -2.1507e-04,  4.6434e-04,  ..., -3.5664e-04,\n",
       "            2.1090e-04, -7.1861e-05]],\n",
       "\n",
       "         [[-6.3568e-05, -2.0878e-04,  7.6659e-05,  ..., -4.1716e-04,\n",
       "           -1.4636e-04,  8.3708e-04]],\n",
       "\n",
       "         [[ 1.8580e-04, -1.9218e-04,  3.6756e-04,  ..., -2.7718e-04,\n",
       "           -4.9496e-04, -1.1262e-05]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-2.2268e-04, -2.8858e-04,  6.8349e-04,  ..., -1.6078e-05,\n",
       "           -5.1998e-04, -1.0316e-04]],\n",
       "\n",
       "         [[-2.3383e-04, -1.4468e-04, -3.8647e-04,  ...,  1.1349e-04,\n",
       "           -3.7390e-04, -1.0186e-04]],\n",
       "\n",
       "         [[-6.3628e-05, -2.6186e-04, -4.2481e-05,  ..., -1.7399e-04,\n",
       "           -4.1607e-04,  6.0721e-04]]]], device='cuda:0')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(out_offload - out_dot) # the difference should be super small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e64cf209",
   "metadata": {},
   "outputs": [],
   "source": [
    "outs, max_lse = None, None\n",
    "new_denominator = None\n",
    "attn_output = None\n",
    "new_lse_full = None\n",
    "\n",
    "for i in range(len(k_chunks)):\n",
    "    out_, lse_ = memory_efficient_attention_partial(q_, k_chunks[i], v_chunks[i])\n",
    "    lse_ = lse_.transpose(1, 2)\n",
    "\n",
    "    if i == 0:\n",
    "        max_lse = lse_\n",
    "        adjust_factors = torch.ones_like(lse_).unsqueeze(-1)\n",
    "        new_denominator = adjust_factors\n",
    "        attn_output = out_ * adjust_factors\n",
    "        new_lse_full = lse_\n",
    "    else:\n",
    "        new_max_lse = torch.maximum(max_lse, lse_)\n",
    "        \n",
    "        old_adjust_factors = torch.exp(max_lse - new_max_lse).unsqueeze(-1)\n",
    "        new_adjust_factors = torch.exp(lse_ - new_max_lse).unsqueeze(-1)\n",
    "        \n",
    "        new_denominator = old_adjust_factors * new_denominator + new_adjust_factors\n",
    "        attn_output = old_adjust_factors * attn_output + new_adjust_factors * out_\n",
    "        new_lse_full = new_max_lse + torch.log(torch.exp(new_lse_full - new_max_lse) + torch.exp(lse_ - new_max_lse))\n",
    "        \n",
    "        max_lse = new_max_lse\n",
    "\n",
    "attn_output = attn_output / new_denominator\n",
    "attn_output = attn_output.transpose(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f19ac427",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            3.7253e-09,  0.0000e+00]],\n",
       "\n",
       "         [[ 1.4901e-08,  0.0000e+00,  0.0000e+00,  ...,  1.8626e-09,\n",
       "            2.9802e-08,  1.8626e-09]],\n",
       "\n",
       "         [[ 0.0000e+00, -1.4901e-08, -1.1176e-08,  ..., -1.1176e-08,\n",
       "           -7.4506e-09, -1.4901e-08]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-3.7253e-09, -1.1176e-08,  0.0000e+00,  ..., -8.3819e-09,\n",
       "            0.0000e+00, -3.7253e-09]],\n",
       "\n",
       "         [[ 7.6834e-09,  7.4506e-09, -1.9558e-08,  ...,  1.4901e-08,\n",
       "            0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "         [[ 1.4901e-08, -1.4901e-08, -2.4214e-08,  ...,  1.4901e-08,\n",
       "            0.0000e+00, -2.9802e-08]]]], device='cuda:0')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_output - out_offload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c17fb0ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16, 1, 128])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "59a061bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16, 1, 128])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_offload.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "10d63086",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1., device='cuda:0')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(attn_output.sign() == out_offload.sign()).float().mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.10",
   "language": "python",
   "name": "python3.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
