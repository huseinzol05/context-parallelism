{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce1923b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xformers.ops.fmha import (\n",
    "    memory_efficient_attention_forward,\n",
    "    memory_efficient_attention_backward, \n",
    "    memory_efficient_attention_partial,\n",
    "    merge_attentions\n",
    ")\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ddecb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = torch.randn(1, 21, 1, 128).cuda().to(torch.bfloat16)\n",
    "k = torch.randn(1, 21, 100, 128).cuda().to(torch.bfloat16)\n",
    "v = torch.randn(1, 21, 100, 128).cuda().to(torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d45fc22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.03 ms, sys: 945 Âµs, total: 2.98 ms\n",
      "Wall time: 2.35 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 21, 1, 128])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "out_dot = torch.nn.functional.scaled_dot_product_attention(q, k, v)\n",
    "out_dot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "061c8c65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 100, 21, 128])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_ = q.transpose(1, 2)\n",
    "k_ = k.transpose(1, 2)\n",
    "v_ = v.transpose(1, 2)\n",
    "v_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd8c60d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "partition_size = 5 # means we split attention into 5 partitions and incrementally calculate it\n",
    "k_chunks = k_.chunk(partition_size, dim = 1)\n",
    "v_chunks = v_.chunk(partition_size, dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5105ca88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 21, 128])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c5b74a0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.4 ms, sys: 35.2 ms, total: 37.6 ms\n",
      "Wall time: 37.3 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 21, 1, 128])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# https://github.com/ScalingIntelligence/hydragen/blob/main/hydragen/attention.py#L21\n",
    "outs, lses = [], []\n",
    "for i in range(len(k_chunks)):\n",
    "    out_, lse_ = memory_efficient_attention_partial(q_, k_chunks[i], v_chunks[i])\n",
    "    outs.append(out_)\n",
    "    lses.append(lse_)\n",
    "    \n",
    "outs = torch.stack(outs)\n",
    "lses = torch.stack(lses)\n",
    "\n",
    "max_lse = lses.max(0).values\n",
    "lse_full = (max_lse + (lses - max_lse[None]).exp().sum(dim=0).log())\n",
    "\n",
    "adjust_factors = (lses - max_lse[None]).exp()\n",
    "adjust_factors = adjust_factors.transpose(2, 3).unsqueeze(-1)\n",
    "new_denominator = adjust_factors.sum(0)\n",
    "out_offload = ((outs * adjust_factors).sum(0) / new_denominator).transpose(1, 2)\n",
    "out_offload.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f025889",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.3315,  0.1697, -0.0938,  ...,  0.1379,  0.1604, -0.1074]],\n",
       "\n",
       "         [[-0.0157,  0.0269, -0.1003,  ...,  0.1017, -0.1896,  0.1197]],\n",
       "\n",
       "         [[-0.1364,  0.3072,  0.1040,  ..., -0.0357,  0.0404, -0.0206]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.1383, -0.0318, -0.0719,  ...,  0.0949,  0.0897,  0.0715]],\n",
       "\n",
       "         [[ 0.0010,  0.0593, -0.1481,  ..., -0.0633,  0.1171,  0.0734]],\n",
       "\n",
       "         [[-0.1108,  0.1146, -0.0208,  ..., -0.2461,  0.0471,  0.0960]]]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_offload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "285ec478",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-4.9028e-04,  7.9504e-04, -5.3100e-05,  ...,  2.3939e-04,\n",
       "            2.0193e-04,  4.1224e-05]],\n",
       "\n",
       "         [[ 6.1432e-05,  8.3534e-05,  2.5561e-04,  ..., -3.0986e-04,\n",
       "            7.8350e-04,  6.0281e-04]],\n",
       "\n",
       "         [[ 3.0224e-04,  5.7122e-04, -5.0990e-04,  ...,  1.9699e-04,\n",
       "           -1.5710e-04, -4.4663e-04]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-6.0607e-04, -4.2256e-05, -8.3089e-05,  ..., -3.2692e-04,\n",
       "           -1.2110e-04,  7.2782e-04]],\n",
       "\n",
       "         [[ 1.8294e-04,  1.7340e-04,  3.7739e-04,  ...,  2.1625e-04,\n",
       "           -9.7543e-05, -3.3285e-04]],\n",
       "\n",
       "         [[ 7.0259e-05, -1.2022e-04,  1.6701e-04,  ..., -9.4342e-04,\n",
       "            4.4819e-04, -1.8079e-04]]]], device='cuda:0')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(out_offload - out_dot) # the difference should be super small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e64cf209",
   "metadata": {},
   "outputs": [],
   "source": [
    "outs, max_lse = None, None\n",
    "new_denominator = None\n",
    "attn_output = None\n",
    "new_lse_full = None\n",
    "\n",
    "for i in range(len(k_chunks)):\n",
    "    out_, lse_ = memory_efficient_attention_partial(q_, k_chunks[i], v_chunks[i])\n",
    "    lse_ = lse_.transpose(1, 2)\n",
    "\n",
    "    if i == 0:\n",
    "        max_lse = lse_\n",
    "        adjust_factors = torch.ones_like(lse_).unsqueeze(-1)\n",
    "        new_denominator = adjust_factors\n",
    "        attn_output = out_ * adjust_factors\n",
    "        new_lse_full = lse_\n",
    "    else:\n",
    "        new_max_lse = torch.maximum(max_lse, lse_)\n",
    "        \n",
    "        old_adjust_factors = torch.exp(max_lse - new_max_lse).unsqueeze(-1)\n",
    "        new_adjust_factors = torch.exp(lse_ - new_max_lse).unsqueeze(-1)\n",
    "        \n",
    "        new_denominator = old_adjust_factors * new_denominator + new_adjust_factors\n",
    "        attn_output = old_adjust_factors * attn_output + new_adjust_factors * out_\n",
    "        new_lse_full = new_max_lse + torch.log(torch.exp(new_lse_full - new_max_lse) + torch.exp(lse_ - new_max_lse))\n",
    "        \n",
    "        max_lse = new_max_lse\n",
    "\n",
    "attn_output = attn_output / new_denominator\n",
    "attn_output = attn_output.transpose(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f19ac427",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-2.9802e-08,  2.9802e-08,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  7.4506e-09]],\n",
       "\n",
       "         [[ 1.3039e-08, -1.8626e-09,  0.0000e+00,  ...,  7.4506e-09,\n",
       "            1.4901e-08,  0.0000e+00]],\n",
       "\n",
       "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            3.7253e-09,  0.0000e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.0000e+00,  3.7253e-09,  0.0000e+00,  ..., -7.4506e-09,\n",
       "           -7.4506e-09,  7.4506e-09]],\n",
       "\n",
       "         [[-1.8626e-09,  3.7253e-09,  0.0000e+00,  ..., -7.4506e-09,\n",
       "           -7.4506e-09,  1.4901e-08]],\n",
       "\n",
       "         [[ 1.4901e-08,  7.4506e-09, -7.4506e-09,  ...,  0.0000e+00,\n",
       "            7.4506e-09,  0.0000e+00]]]], device='cuda:0')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_output - out_offload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "22cde241",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[5.0803],\n",
       "         [5.1817],\n",
       "         [5.2088],\n",
       "         [4.8658],\n",
       "         [4.9444],\n",
       "         [4.9638],\n",
       "         [5.4463],\n",
       "         [5.1694],\n",
       "         [5.2293],\n",
       "         [5.3548],\n",
       "         [5.1799],\n",
       "         [4.9810],\n",
       "         [5.1273],\n",
       "         [5.2139],\n",
       "         [5.1583],\n",
       "         [5.1400],\n",
       "         [4.9378],\n",
       "         [5.0265],\n",
       "         [5.1528],\n",
       "         [5.2309],\n",
       "         [5.0253]]], device='cuda:0')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lse_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eac6ccca",
   "metadata": {},
   "outputs": [],
   "source": [
    "lse_full.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caba15c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.10",
   "language": "python",
   "name": "python3.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
