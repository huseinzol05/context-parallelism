{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3000d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce1923b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from xformers.ops.fmha import (\n",
    "    memory_efficient_attention_forward,\n",
    "    memory_efficient_attention_backward, \n",
    "    memory_efficient_attention_partial,\n",
    "    merge_attentions\n",
    ")\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d855d3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "head_num = 16\n",
    "dim = 128\n",
    "seq_len = 100\n",
    "chunk_size = 4\n",
    "batch_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35ffb759",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = torch.randn(batch_size, head_num, seq_len, dim).cuda().to(torch.bfloat16)\n",
    "k = torch.randn(batch_size, head_num, seq_len, dim).cuda().to(torch.bfloat16)\n",
    "v = torch.randn(batch_size, head_num, seq_len, dim).cuda().to(torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66ef8e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dot = torch.nn.functional.scaled_dot_product_attention(q, k, v, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d62d745",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16, 100, 128])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_dot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "156f7471",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 100, 16, 128])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_ = q.transpose(1, 2)\n",
    "k_ = k.transpose(1, 2)\n",
    "v_ = v.transpose(1, 2)\n",
    "v_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43b795e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_chunks = q_.chunk(chunk_size, dim = 1)\n",
    "k_chunks = k_.chunk(chunk_size, dim = 1)\n",
    "v_chunks = v_.chunk(chunk_size, dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cca85180",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_block = q_chunks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7844ace3",
   "metadata": {},
   "outputs": [],
   "source": [
    "outs, max_lse = None, None\n",
    "new_denominator = None\n",
    "attn_output = None\n",
    "new_lse_full = None\n",
    "\n",
    "for i in range(len(k_chunks)):\n",
    "    out_, lse_ = memory_efficient_attention_partial(Q_block, k_chunks[i], v_chunks[i])\n",
    "    lse_ = lse_.transpose(1, 2)\n",
    "\n",
    "    if i == 0:\n",
    "        max_lse = lse_\n",
    "        adjust_factors = torch.ones_like(lse_).unsqueeze(-1)\n",
    "        new_denominator = adjust_factors\n",
    "        attn_output = out_ * adjust_factors\n",
    "        new_lse_full = lse_\n",
    "    else:\n",
    "        new_max_lse = torch.maximum(max_lse, lse_)\n",
    "        \n",
    "        old_adjust_factors = torch.exp(max_lse - new_max_lse).unsqueeze(-1)\n",
    "        new_adjust_factors = torch.exp(lse_ - new_max_lse).unsqueeze(-1)\n",
    "        \n",
    "        new_denominator = old_adjust_factors * new_denominator + new_adjust_factors\n",
    "        attn_output = old_adjust_factors * attn_output + new_adjust_factors * out_\n",
    "        new_lse_full = new_max_lse + torch.log(torch.exp(new_lse_full - new_max_lse) + torch.exp(lse_ - new_max_lse))\n",
    "        \n",
    "        max_lse = new_max_lse\n",
    "\n",
    "attn_output = attn_output / new_denominator\n",
    "attn_output = attn_output.transpose(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "574ea9e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 16, 25, 128]), torch.Size([1, 16, 100, 128]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_output.shape, out_dot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c43bd075",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9992, device='cuda:0')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(attn_output.sign() == out_dot[:,:,:25].sign()).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a66fa8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 55, 118, 109,  94,  58,  28,  32,  11, 109, 109,  74, 118,  56,  41,\n",
       "          118,  53, 109,  55, 101,  22, 114,  44,  44,  98, 114],\n",
       "         [108,  47,   4,  43,  20, 115,  61,  52,  31, 106, 119, 119,  80, 108,\n",
       "           20, 103,  47,  39, 108,  73, 115,  47,  47,  32, 114],\n",
       "         [  3,  11,   3,  45,   3,   8,   3,   3,   3,   3,   3,   3,   3,  47,\n",
       "            3,  89,   3, 111,   3,   3,   3, 126,  17,  42,   3],\n",
       "         [110,   7,  32, 121,  11, 110, 112,  21,  45,  45,  21,  59,  81,  32,\n",
       "           32,   8,  32,  39,  39,   8,  81,  59,   9,  81,  96],\n",
       "         [ 60,  12, 127,  60, 127,  15,  12,  64,  12,  34,  78,  57, 109,  57,\n",
       "           12,  57,  57,  57,  72,  15,  57,  12, 127,  72, 116],\n",
       "         [ 16,  85,  32,  10,  91,  64,  32,  32,  19,  19,  16, 118,  19,  49,\n",
       "           91,  19,  19,  32, 125,  35,  93,  19,  49,  19,  19],\n",
       "         [ 76,  83,  76,  76, 104,  76, 104,  76,  26,  87,  14,  40, 117,  73,\n",
       "           51,  84, 104,  70,  77,  87,  14,  76,  87,  76, 117],\n",
       "         [ 82,  39,  50,  48,  83,  42,  42,  42, 102,  42,  93, 104,  66,  70,\n",
       "           66,  37, 113,  66,  67,  70, 114,  42,  42, 126,  48],\n",
       "         [  6,   6,  69,   6, 114,   1,   1,  92,  10,  68,  68,   1,  46,  68,\n",
       "          114,  69,  37,  69,   1,   2, 104,  68,  68,   6, 114],\n",
       "         [ 78,  54,  14,  48,  22, 117,  48,  14,   0,   4,  50, 102,  61,  78,\n",
       "           14, 110,  48,  14,  14,  25,  93,  54, 103, 112,  94],\n",
       "         [ 59,  59,  66,   1, 114, 115,  54,  73,   1,  41, 114, 127,   1,  10,\n",
       "           15,  66,  10,  28,  54, 111, 114,  40,  10,   1,  10],\n",
       "         [ 13, 113,  23,  23,  27,  13, 106,  87,  53,  23,  23, 102,  82,  23,\n",
       "          102,  65,  82, 112,  65,  51,  55,  23,   0, 106, 108],\n",
       "         [ 88, 119, 124, 121,  11,  62,  88,  43, 109, 125,  18,  62,  88, 108,\n",
       "          125,  88, 118,  11, 119,  67,  54, 116, 108,  11,  62],\n",
       "         [ 32, 110,  58,  35,  77,  67, 110,  28,  27,  67,  35,  59,  27,  35,\n",
       "           59, 102,  58,  61, 110,  43, 112, 110,  54, 122,  10],\n",
       "         [ 55,  18,  71,  90, 123,  90,  90,  25, 121,  18,   7, 123,  90,   1,\n",
       "           90,  62,  90,   7,   1,   0,   1,  18, 111, 126,  55],\n",
       "         [ 12,  92,  73, 102, 123,  98,  17,  92,   1,  62, 123,  28,  17,  56,\n",
       "           92,  73,  50,  92,  92,  92, 120,  92,  92, 123,  73]]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_dot[:,:,:25].argmax(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "784506f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 55, 118, 109,  94,  58,  28,  32,  11, 109, 109,  74, 118,  56,  41,\n",
       "          118,  53, 109,  55, 101,  22, 114,  44,  44,  98, 114],\n",
       "         [108,  47,   4,  43,  20, 115,  61,  52,  31, 106, 119, 119,  80, 108,\n",
       "           20, 103,  47,  39, 108,  73, 115,  47,  47,  32, 114],\n",
       "         [  3,  11,  55,  45,   3,   8,   3,   3,   3,   3,   3,   3,   3,  47,\n",
       "            3,  89,   3, 111,   3,   3,   3, 126,  17,  42,   3],\n",
       "         [110,   7,  32, 121,  11, 110, 112,  21,  45,  45,  21,  59,  81,  32,\n",
       "           32,   8,  32,  39,  39,   8,  81,  59,   9,  81,  96],\n",
       "         [ 60,  12, 127,  60, 127,  15,  12,  64,  12,  34,  78,  57, 109,  57,\n",
       "           12,  57,  57,  57,  72,  15,  57,  12, 127,  72, 116],\n",
       "         [ 16,  85,  32,  10,  91,  64,  32,  32,  19,  19,  16, 118,  19,  49,\n",
       "           91,  19,  19,  32, 125,  35,  93,  19,  49,  19,  19],\n",
       "         [ 76,  83,  76,  76, 104,  76, 104,  76,  26,  87,  14,  40, 117,  73,\n",
       "           51,  84, 104,  70,  77,  87,  14,  76,  87,  76, 117],\n",
       "         [ 82,  39,  50,  48,  83,  42,  42,  42, 102,  42,  93, 104,  66,  70,\n",
       "           66,  37, 113,  66,  67,  70, 114,  42,  42, 126,  48],\n",
       "         [  6,   6,  69,   6, 114,   1,   1,  92,  10,  68,  68,   1,  46,  68,\n",
       "          114,  69,  37,  69,   1,   2, 104,  68,  68,   6, 114],\n",
       "         [ 78,  54,  14,  48,  22, 117,  48,  14,   0,   4,  50, 102,  61,  78,\n",
       "           14, 110,  48,  14,  14,  25,  93,  54, 103, 112,  94],\n",
       "         [ 59,  59,  66,   1, 114, 115,  54,  73,   1,  41, 114, 127,   1,  10,\n",
       "           15,  66,  10,  28,  54, 111, 114,  40,  10,   1,  10],\n",
       "         [ 13, 113,  23,  23,  27,  13, 106,  87,  53,  23,  23, 102,  82,  23,\n",
       "          102,  65,  82, 112,  65,  51,  55,  23,   0, 106, 108],\n",
       "         [ 88, 119, 124, 121,  11,  62,  88,  43, 109, 125,  18,  62,  88, 108,\n",
       "          125,  88, 118,  11, 119,  67,  54, 116, 108,  11,  62],\n",
       "         [ 32, 110,  58,  35,  77,  67, 110,  28,  27,  67,  35,  59,  27,  35,\n",
       "           59, 102,  58,  61, 110,  43, 112, 110,  54, 122,  10],\n",
       "         [ 55,  18,  71,  90, 123,  90,  90,  25, 121,  18,   7, 123,  90,   1,\n",
       "           90,  62,  90,   7,   1,   0,   1,  18, 111, 126,  55],\n",
       "         [ 12,  92,  73, 102, 123,  98,  17,  92,   1,  62, 123,  28,  17,  56,\n",
       "           92,  73,  50,  92,  92,  92, 120,  92,  92, 123,  73]]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_output.argmax(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e828ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_attention(Q_block, k_chunks, v_chunks):\n",
    "    outs, max_lse = None, None\n",
    "    new_denominator = None\n",
    "    attn_output = None\n",
    "    new_lse_full = None\n",
    "\n",
    "    for i in range(len(k_chunks)):\n",
    "        out_, lse_ = memory_efficient_attention_partial(Q_block, k_chunks[i], v_chunks[i])\n",
    "        lse_ = lse_.transpose(1, 2)\n",
    "\n",
    "        if i == 0:\n",
    "            max_lse = lse_\n",
    "            adjust_factors = torch.ones_like(lse_).unsqueeze(-1)\n",
    "            new_denominator = adjust_factors\n",
    "            attn_output = out_ * adjust_factors\n",
    "            new_lse_full = lse_\n",
    "        else:\n",
    "            new_max_lse = torch.maximum(max_lse, lse_)\n",
    "\n",
    "            old_adjust_factors = torch.exp(max_lse - new_max_lse).unsqueeze(-1)\n",
    "            new_adjust_factors = torch.exp(lse_ - new_max_lse).unsqueeze(-1)\n",
    "\n",
    "            new_denominator = old_adjust_factors * new_denominator + new_adjust_factors\n",
    "            attn_output = old_adjust_factors * attn_output + new_adjust_factors * out_\n",
    "            new_lse_full = new_max_lse + torch.log(torch.exp(new_lse_full - new_max_lse) + torch.exp(lse_ - new_max_lse))\n",
    "\n",
    "            max_lse = new_max_lse\n",
    "    \n",
    "    return attn_output, max_lse, new_lse_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2665c4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_output_0, max_lse_0, new_lse_full_0 = local_attention(Q_block, k_chunks[:2], v_chunks[:2])\n",
    "attn_output_1, max_lse_1, new_lse_full_1 = local_attention(Q_block, k_chunks[2:], v_chunks[2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0474382e",
   "metadata": {},
   "outputs": [],
   "source": [
    "denominators = []\n",
    "adjusted_outputs = []\n",
    "\n",
    "all_lses = torch.cat([lse.unsqueeze(0) for lse in max_lses], dim=0)\n",
    "global_max_lse = torch.max(all_lses, dim=0)[0]\n",
    "\n",
    "for i, (output, lse) in enumerate(zip(attn_outputs, max_lses)):\n",
    "    adjust_factor = torch.exp(lse - global_max_lse).unsqueeze(-1)\n",
    "\n",
    "    adjusted_outputs.append(output * adjust_factor)\n",
    "    denominators.append(adjust_factor)\n",
    "\n",
    "final_output = torch.zeros_like(adjusted_outputs[0])\n",
    "final_denominator = torch.zeros_like(denominators[0])\n",
    "\n",
    "for adj_output, denom in zip(adjusted_outputs, denominators):\n",
    "    final_output += adj_output\n",
    "    final_denominator += denom\n",
    "\n",
    "merged_output = (final_output / final_denominator).transpose(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e8e2723d",
   "metadata": {},
   "outputs": [],
   "source": [
    "denominators = []\n",
    "adjusted_outputs = []\n",
    "\n",
    "for i, (output, lse) in enumerate(zip(attn_outputs, max_lses)):\n",
    "    adjust_factor = torch.exp(lse - global_max_lse).unsqueeze(-1)\n",
    "\n",
    "    adjusted_outputs.append(output * adjust_factor)\n",
    "    denominators.append(adjust_factor)\n",
    "\n",
    "final_output = torch.zeros_like(adjusted_outputs[0])\n",
    "final_denominator = torch.zeros_like(denominators[0])\n",
    "\n",
    "for adj_output, denom in zip(adjusted_outputs, denominators):\n",
    "    final_output += adj_output\n",
    "    final_denominator += denom\n",
    "\n",
    "merged_output = (final_output / final_denominator).transpose(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4a5fecfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9975, device='cuda:0')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(merged_output.argmax(-1) == out_dot[:,:,:25].argmax(-1)).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4661b684",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9992, device='cuda:0')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(merged_output.sign() == out_dot[:,:,:25].sign()).float().mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.10",
   "language": "python",
   "name": "python3.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
