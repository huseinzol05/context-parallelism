{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce1923b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from xformers.ops.fmha import (\n",
    "    memory_efficient_attention_forward,\n",
    "    memory_efficient_attention_backward, \n",
    "    memory_efficient_attention_partial,\n",
    "    merge_attentions\n",
    ")\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d855d3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "head_num = 16\n",
    "dim = 128\n",
    "seq_len = 100\n",
    "chunk_size = 5\n",
    "batch_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35ffb759",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = torch.randn(batch_size, head_num, seq_len, dim).cuda().to(torch.bfloat16)\n",
    "k = torch.randn(batch_size, head_num, seq_len, dim).cuda().to(torch.bfloat16)\n",
    "v = torch.randn(batch_size, head_num, seq_len, dim).cuda().to(torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66ef8e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dot = torch.nn.functional.scaled_dot_product_attention(q, k, v, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d62d745",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16, 100, 128])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_dot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "156f7471",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 100, 16, 128])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_ = q.transpose(1, 2)\n",
    "k_ = k.transpose(1, 2)\n",
    "v_ = v.transpose(1, 2)\n",
    "v_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43b795e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_chunks = q_.chunk(chunk_size, dim = 1)\n",
    "k_chunks = k_.chunk(chunk_size, dim = 1)\n",
    "v_chunks = v_.chunk(chunk_size, dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cca85180",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_block = q_chunks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7844ace3",
   "metadata": {},
   "outputs": [],
   "source": [
    "outs, max_lse = None, None\n",
    "new_denominator = None\n",
    "attn_output = None\n",
    "new_lse_full = None\n",
    "\n",
    "for i in range(len(k_chunks)):\n",
    "    out_, lse_ = memory_efficient_attention_partial(Q_block, k_chunks[i], v_chunks[i])\n",
    "    lse_ = lse_.transpose(1, 2)\n",
    "\n",
    "    if i == 0:\n",
    "        max_lse = lse_\n",
    "        adjust_factors = torch.ones_like(lse_).unsqueeze(-1)\n",
    "        new_denominator = adjust_factors\n",
    "        attn_output = out_ * adjust_factors\n",
    "        new_lse_full = lse_\n",
    "    else:\n",
    "        new_max_lse = torch.maximum(max_lse, lse_)\n",
    "        \n",
    "        old_adjust_factors = torch.exp(max_lse - new_max_lse).unsqueeze(-1)\n",
    "        new_adjust_factors = torch.exp(lse_ - new_max_lse).unsqueeze(-1)\n",
    "        \n",
    "        new_denominator = old_adjust_factors * new_denominator + new_adjust_factors\n",
    "        attn_output = old_adjust_factors * attn_output + new_adjust_factors * out_\n",
    "        new_lse_full = new_max_lse + torch.log(torch.exp(new_lse_full - new_max_lse) + torch.exp(lse_ - new_max_lse))\n",
    "        \n",
    "        max_lse = new_max_lse\n",
    "\n",
    "attn_output = attn_output / new_denominator\n",
    "attn_output = attn_output.transpose(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c43bd075",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9993, device='cuda:0')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(attn_output.sign() == out_dot[:,:,:20].sign()).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a66fa8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[102, 126,   8,  62, 126,  91,  46,  87,   9, 126,  77,   9, 113, 126,\n",
       "           54, 126,  42,  35,   7, 123],\n",
       "         [  9,  27,  21, 104,  30,  31,  14,   9,  57,  27, 103, 124,  51,  81,\n",
       "           21,  61,  30,  90,   9,  92],\n",
       "         [  0,  43,  43,  43,  61,  43,  16,  43, 118,   0,   9,   9,  61, 118,\n",
       "           91,   9,  43,  61,  43,   0],\n",
       "         [ 13,  13,  98,  41,   2,  38,  13,  95, 124, 113,  35, 117,  98,  97,\n",
       "          107,  34,  21,  41,  41,   4],\n",
       "         [122,  81,  44, 109, 109,  81,  66, 103,  66, 104,  93, 101,   5,  38,\n",
       "           11, 103,  66,  68,  58,  66],\n",
       "         [102, 125,  50,  96,   0, 103,  96,  31,  91,  64,   5, 124, 125,   5,\n",
       "            1, 103,   7, 125,  36,  64],\n",
       "         [ 68,  83,  56,  99,  99, 120, 112,  45,   8,  58, 120,  99,  56, 120,\n",
       "          123,  77,  92,  77, 123,  92],\n",
       "         [ 85,  85,  81,  38,  79,  20,  97,  51,  78,  38,  78,   7,  77,  57,\n",
       "           20,  23,  97,  51,  34,  97],\n",
       "         [ 53,  58,   0, 117,  59, 123, 122,  33,  43,  55, 123,  17,  77, 126,\n",
       "            0,  33,  40,   0,  52,   7],\n",
       "         [ 53,  40,  53, 112,  53, 108,  32,  82,  34,  53,  53,  34,  25,  94,\n",
       "           95,  68, 120,  98,   8,  44],\n",
       "         [120,  94,  63,  23,  60,  12,  63,  63,  53,  98,  13,  53,  89,  89,\n",
       "           96,  13,  60,  65,  78,  78],\n",
       "         [  6, 109, 111,  39,   9,   6,   9,  11, 109, 123,   9, 123,  62,   9,\n",
       "          123,  62,   9,   9,   9,   9],\n",
       "         [ 90,  46,  16, 119, 115,  90, 126,  59,  45,  46,  73,  84, 127, 127,\n",
       "           43,  43,  16, 123, 127,  84],\n",
       "         [ 79,   3,  97,  93,  25,  67,  97,  19,  50,  93,  78,  97,  34, 121,\n",
       "           11,  97, 112,  68,  52,  97],\n",
       "         [ 24,  45,   3, 104,   6,  32,  62, 105,   0,  32,  20,  66, 110,  16,\n",
       "           20, 110,  61,  45,  63,   6],\n",
       "         [ 74,  88,  82,  28,  44,   2,  30, 102,  63,  55, 104,  45,  35,  30,\n",
       "           24,  44,  88,  55,  63,  55]]], device='cuda:0')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_dot[:,:,:20].argmax(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "784506f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[102, 126,   8,  62, 126,  91,  46,  87, 113, 126,  77,   9, 113, 126,\n",
       "           54, 126,  42,  35,   7, 123],\n",
       "         [  9,  27,  21, 104,  30,  31,  14,   9,  57,  27, 103, 124,  51,  81,\n",
       "           21,  61,  30,  90,   9,  92],\n",
       "         [  0,  43,  43,  43,  61,  43,  16,  43, 118,   0,   9,   9,  61, 118,\n",
       "           91,   9,  43,  61,  43,   0],\n",
       "         [ 13,  13,  98,  41,   2,  38,  13,  95, 124, 113,  35, 117,  98,  97,\n",
       "          107,  34,  21,  41,  41,   4],\n",
       "         [122,  81,  44, 109, 109,  81,  66, 103,  66, 104,  93, 101,   5,  38,\n",
       "           11, 103,  66,  68,  58,  66],\n",
       "         [102, 125,  50,  96,   0, 103,  96,  31,  91,  64,   5, 124, 125,   5,\n",
       "            1, 103,   7, 125,  36,  64],\n",
       "         [ 68,  83,  56,  99,  99, 120, 112,  45,   8,  58, 120,  99,  56, 120,\n",
       "          123,  77,  92,  77, 123,  92],\n",
       "         [ 85,  85,  81,  38,  79,  20,  97,  51,  78,  81,  78,   7,  77,  57,\n",
       "           20,  23,  97,  51,  34,  97],\n",
       "         [ 53,  58,   0, 117,  59, 123, 122,  33,  43,  55, 123,  17,  77, 126,\n",
       "            0,  33,  40,   0,  52,   7],\n",
       "         [ 53,  40,  53, 112,  53, 108,  32,  82,  34,  53,  53,  34,  25,  94,\n",
       "           95,  68, 120,  98,   8,  44],\n",
       "         [120,  94,  63,  23,  60,  12,  63,  63,  53,  98,  13,  53,  89,  89,\n",
       "           96,  13,  60,  65,  78,  78],\n",
       "         [  6, 109, 111,  39,   9,   6,   9,  11, 109, 123,   9, 123,  62,   9,\n",
       "          123,  62,   9,   9,   9,   9],\n",
       "         [ 90,  46,  16, 119, 115,  90, 126,  59,  45,  46,  73,  84, 127, 127,\n",
       "           43,  43,  16, 123, 127,  84],\n",
       "         [ 79,   3,  97,  93,  25,  67,  97,  19,  50,  93,  78,  97,  34, 121,\n",
       "           11,  97, 112,  68,  52,  97],\n",
       "         [ 24,  45,   3, 104,   6,  32,  62, 105,   0,  32,  20,  66, 110,  16,\n",
       "           20, 110,  61,  45,  63,   6],\n",
       "         [ 74,  88,  82,  28,  44,   2,  30, 102,  63,  55, 104,  45,  35,  30,\n",
       "           24,  44,  88,  55,  63,  55]]], device='cuda:0')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_output.argmax(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e828ccd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.10",
   "language": "python",
   "name": "python3.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
